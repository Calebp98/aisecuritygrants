---
layout: default
---

# Grants and Investments for AI Security Projects

- Our partners are currently looking to fund projects that could dramatically improve the security of frontier AI systems. In the past our partners have made grants ranging from 10k to 100mil+.

- If you are looking for funding [please fill out this form](#).

- If you're not looking for funding but are considering joining or starting a project in this space, [please fill out this form](#).

## Our thesis:

- We expect very powerful AI systems (e.g. AI systems that are capable of automating the majority of intellectual labour) to be built in the [next](https://milesbrundage.substack.com/p/times-up-for-ai-policy) [five](https://www.lesswrong.com/posts/K2D45BNxnZjdpSX2j/ai-timelines) years.
- The current security posture of frontier labs, hyperscalers, and other critical parts of the AI supply chain is [insufficient for defending against sophisticated cyber attacks](https://www.rand.org/pubs/research_reports/RRA2849-1.html).
- Defending against sophisticated cyber attacks could [significantly decrease the risk of a catastrophe](https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/) and increase the chance of humanity flourishing.
- We suspect there are many high leverage projects that could be started by cybersecurity researchers, engineers, and policymakers; providing a path to funding could significantly increase the number of high velocity projects that start in the next year.

## Our advisors include staff from:

// ... existing code ...

## Our advisors include staff from:

<div class="advisor-grid">
  <ul>
    <li><a href="https://www.crowdstrike.com">CrowdStrike</a></li>
    <li><a href="https://www.paloaltonetworks.com">Palo Alto Networks</a></li>
    <li><a href="https://www.anthropic.com">Anthropic</a></li>
    <li><a href="https://deepmind.google/">Google Deepmind</a></li>
    <li><a href="https://www.llama.com/">Meta</a></li>
    <li><a href="https://www.2430group.org">2430 Group</a></li>
    <li><a href="https://www.trailofbits.com">Trail of Bits</a></li>
    <li><a href="https://www.mit.edu">MIT</a></li>
  </ul>

  <ul>
    <li><a href="https://www.schmidtfutures.com">Schmidt Futures</a></li>
    <li><a href="https://www.polaris.com">Polaris</a></li>
    <li><a href="https://cohere.ai">Cohere</a></li>
    <li><a href="https://securityandtechnology.org/">Institute for Security and Technology</a></li>
    <li><a href="https://www.rand.org">RAND Corporation</a></li>
    <li><a href="https://www.aisi.gov.uk">UK AISI</a></li>
    <li><a href="https://www.nist.gov/aisi">US AISI</a></li>
  </ul>

  <ul>
    <li><a href="https://progress.institute">Institute for Progress</a></li>
    <li><a href="https://www.patternlabs.ai">Pattern Labs</a></li>
    <li><a href="https://risczero.com">Zero RISC</a></li>
    <li>Dreadnode</li>
    <li><a href="https://confidentialcomputing.io">Confidential Computing Consortium</a></li>
    <li><a href="https://halcyonfutures.org/">Halcyon Futures</a></li>
  </ul>
</div>

_If you are a funder and would like to explore partnering with us please email [caleb] [at] [airiskfund.com]. This project is supported by the [AI Security Forum](aisecurity.forum)._
