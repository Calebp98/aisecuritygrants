---
layout: default
---

# Grants and Investments for AI Security Projects

- Our partners are actively funding projects aimed at strengthening frontier AI systems security, with previous grants ranging from $10,000 to $100M+.

- If you are looking for funding [please fill out this form](#).

- If you're not looking for funding but are considering joining or starting a project in this space, [please fill out this form](#).

## Our thesis:

- We expect very powerful AI systems (e.g. AI systems that are capable of automating the majority of intellectual labour) to be built in the [next](https://milesbrundage.substack.com/p/times-up-for-ai-policy) [five](https://www.lesswrong.com/posts/K2D45BNxnZjdpSX2j/ai-timelines) years.
- The current security posture of frontier labs, hyperscalers, and other critical parts of the AI supply chain is [insufficient for defending against sophisticated cyber attacks](https://www.rand.org/pubs/research_reports/RRA2849-1.html).
- Defending against sophisticated cyber attacks could [significantly decrease the risk of a catastrophe](https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/) and increase the chance of humanity flourishing.
- We believe cybersecurity researchers, engineers, and policymakers are ready to launch high-impact projects in this space. By providing streamlined funding, we aim to accelerate the development of dozens of critical initiatives over the next 12 months.

## Our advisors include staff from:

<div class="advisor-grid">
  <ul>
    <li><a href="https://www.crowdstrike.com">CrowdStrike</a></li>
    <li><a href="https://www.paloaltonetworks.com">Palo Alto Networks</a></li>
    <li><a href="https://www.anthropic.com">Anthropic</a></li>
    <li><a href="https://deepmind.google/">Google Deepmind</a></li>
    <li><a href="https://www.llama.com/">Meta</a></li>
    <li><a href="https://www.2430group.org">2430 Group</a></li>
    <li><a href="https://www.trailofbits.com">Trail of Bits</a></li>
    <li><a href="https://www.mit.edu">MIT</a></li>
  </ul>

  <ul>
    <li><a href="https://www.schmidtfutures.com">Schmidt Futures</a></li>
    <li><a href="https://cohere.ai">Cohere</a></li>
    <li><a href="https://securityandtechnology.org/">Institute for Security and Technology</a></li>
    <li><a href="https://www.rand.org">RAND Corporation</a></li>
    <li><a href="https://www.aisi.gov.uk">UK AISI</a></li>
    <li><a href="https://www.nist.gov/aisi">US AISI</a></li>
  </ul>

  <ul>
    <li><a href="https://progress.institute">Institute for Progress</a></li>
    <li><a href="https://www.patternlabs.co">Pattern Labs</a></li>
    <li><a href="https://risczero.com">Zero RISC</a></li>
    <li><a href="https://www.dreadnode.io/">Dreadnode</a></li>
    <li><a href="https://confidentialcomputing.io">Confidential Computing Consortium</a></li>
    <li><a href="https://halcyonfutures.org/">Halcyon Futures</a></li>
  </ul>
</div>

_If you're a potential funding partner interested in collaboration, please contact [caleb@airiskfund.com](mailto:caleb@airiskfund.com). This initiative is supported by the [AI Security Forum](https://aisecurity.forum)._
