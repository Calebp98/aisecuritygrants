---
layout: default
---

# Grants and Investments for AI Security Projects

- Our partners are actively funding projects aimed at strengthening frontier AI systems security, with previous grants ranging from $10,000 to $100M+.

- If you are looking for funding [please fill out this form](https://docs.google.com/forms/d/e/1FAIpQLSeehVDxM5sNctQ33CBVuysHia7jp9H4a8TmvhsQnDGH5e5fmg/viewform).

- If you're not looking for funding but are considering joining or starting a project in this space, [please fill out this form](https://docs.google.com/forms/d/e/1FAIpQLSdmHljOxu5mrVYLPia4TNTZrGubzLhHbwbfyipDY7Bz9pRKoQ/viewform).

## Our thesis:

- We expect very powerful AI systems (e.g. AI systems that are capable of automating the majority of intellectual labour) to be built in the [next](https://milesbrundage.substack.com/p/times-up-for-ai-policy) [five](https://www.lesswrong.com/posts/K2D45BNxnZjdpSX2j/ai-timelines) years.
- The current security posture of frontier labs, hyperscalers, and other critical parts of the AI supply chain is [insufficient for defending against sophisticated cyber attacks](https://www.rand.org/pubs/research_reports/RRA2849-1.html).
- Defending against sophisticated cyber attacks could [significantly decrease the risk of a catastrophe](https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/) and increase the chance of humanity flourishing.
- We believe cybersecurity researchers, engineers, and policymakers are ready to launch high-impact projects in this space. By providing streamlined funding, we aim to accelerate the development of dozens of critical initiatives over the next 12 months.

Our advisors include senior technical staff at frontier AI labs, current and former members of the national security community, and leading security researchers.

_Interested in becoming a funding partner? Contact [info@secureaigrants.com](mailto:info@secureaigrants.com)._
